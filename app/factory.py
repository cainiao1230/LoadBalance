import asyncio

import httpx
from fastapi import FastAPI
import redis.asyncio as redis

from .config import settings
from . import runtime
from .routes.task_routes import router as task_router
from .routes.user_routes import router as user_router
from .worker import worker_loop, daily_cleanup_task, daily_cleanup_user_decrypt_log_task
from .rate_limiter import TokenBucketRateLimiter
from .load_balancer import init_servers, get_load_balancer_stats
from .db import engine


def create_app() -> FastAPI:
    app = FastAPI(title="Load-Balance FastAPI", version="1.0.0")
    @app.on_event("startup")
    async def on_startup():
        runtime.redis_client = redis.from_url(settings.redis_url, decode_responses=True)
        # HTTPå®¢æˆ·ç«¯ä¼˜åŒ–é…ç½®ï¼š
        # - http2=True: å¯ç”¨HTTP/2å¤šè·¯å¤ç”¨ï¼ˆå¦‚æœæœåŠ¡å™¨æ”¯æŒï¼Œå¯å¤§å¹…å‡å°‘è¿æ¥æ•°å’Œå»¶è¿Ÿï¼‰
        # - verify=False: ç¦ç”¨SSLè¯ä¹¦éªŒè¯ï¼ˆå†…ç½‘ç¯å¢ƒï¼‰
        # - follow_redirects=False: ä¸è‡ªåŠ¨è·Ÿéšé‡å®šå‘
        runtime.http_b_client = httpx.AsyncClient(
            timeout=httpx.Timeout(30.0), 
            verify=False, 
            follow_redirects=False,
            http2=True,  # å¯ç”¨HTTP/2å¤šè·¯å¤ç”¨
            limits=httpx.Limits(
                max_connections=500,          # æ€»è¿æ¥æ± ä¸Šé™
                max_keepalive_connections=100, # ä¿æ´»è¿æ¥æ•°
                keepalive_expiry=30.0         # ä¿æ´»è¶…æ—¶ï¼ˆç§’ï¼‰
            )
        )
        runtime.b_concurrency_sema = asyncio.Semaphore(settings.b_max_concurrency)
        runtime.b_rate_limiter = TokenBucketRateLimiter(settings.b_rate_limit)
        
        # åˆå§‹åŒ–è´Ÿè½½å‡è¡¡æœåŠ¡å™¨åˆ—è¡¨ï¼ˆä½¿ç”¨å®Œæ•´é…ç½®ï¼ŒåŒ…å«è´¦å·å¯†ç ï¼‰
        init_servers(settings.server_list)
        
        # ä¸åœ¨å¯åŠ¨æ—¶è‡ªåŠ¨åˆ›å»º task è¡¨ï¼ˆä»»åŠ¡ä¸éœ€è¦å­˜ MySQLï¼‰
        # è‹¥éœ€è¦åˆ›å»ºè¡¨è¯·ä½¿ç”¨è¿ç§»å·¥å…·ï¼ˆAlembicï¼‰æˆ–åœ¨æ­¤å¤„æ˜ç¡®è°ƒç”¨
        # å¯åŠ¨Workerå¹¶å‘å¤„ç†å¯†é’¥åŒ…ä»»åŠ¡
        # é˜Ÿåˆ—ä¸­åªæœ‰å¯†é’¥åŒ…ï¼ŒWorkeræ•°é‡ä¸æœåŠ¡å™¨æ•°é‡åŒ¹é…å³å¯
        server_count = len(settings.server_list)
        worker_count = max(server_count, 2)  # è‡³å°‘2ä¸ªWorker
        app.state.workers = [
            asyncio.create_task(worker_loop())
            for _ in range(worker_count)
        ]
        print(f"ğŸš€ å¯åŠ¨äº† {worker_count} ä¸ªWorkerå¹¶å‘å¤„ç†ä»»åŠ¡")

        # å¯åŠ¨æ¯æ—¥å®šæ—¶æ¸…ç†ä»»åŠ¡ï¼ˆä¿å­˜å¼•ç”¨ï¼Œshutdownæ—¶ä¸€å¹¶å–æ¶ˆï¼‰
        app.state.workers.append(asyncio.create_task(daily_cleanup_task()))
        app.state.workers.append(asyncio.create_task(daily_cleanup_user_decrypt_log_task()))

    @app.on_event("shutdown")
    async def on_shutdown():
        # 1. å…ˆå–æ¶ˆæ‰€æœ‰Workerä»»åŠ¡
        workers = getattr(app.state, "workers", [])
        for worker in workers:
            worker.cancel()
        
        # 2. ç­‰å¾…æ‰€æœ‰Workeråœæ­¢ï¼ˆæœ€å¤šç­‰å¾…2ç§’ï¼‰
        if workers:
            try:
                await asyncio.wait_for(
                    asyncio.gather(*workers, return_exceptions=True),
                    timeout=2.0
                )
            except asyncio.TimeoutError:
                print("Workersåœæ­¢è¶…æ—¶ï¼Œå¼ºåˆ¶å…³é—­")
        
        # 3. å…³é—­HTTPå®¢æˆ·ç«¯ï¼ˆåŠ è¶…æ—¶ï¼Œé¿å…HTTP/2 GOAWAYæ¡æ‰‹å¡ä½å…³é—­æµç¨‹ï¼‰
        if runtime.http_b_client:
            try:
                await asyncio.wait_for(runtime.http_b_client.aclose(), timeout=3.0)
            except Exception:
                pass
        
        # 4. é‡Šæ”¾æ•°æ®åº“è¿æ¥æ± ï¼ˆå¿…é¡»åœ¨äº‹ä»¶å¾ªç¯å…³é—­å‰æ‰§è¡Œï¼Œå¦åˆ™ aiomysql __del__ æŠ¥é”™ï¼‰
        await engine.dispose()

        # 5. æœ€åå…³é—­Redisè¿æ¥
        if runtime.redis_client:
            await runtime.redis_client.close()

    app.include_router(task_router)
    app.include_router(user_router)

    @app.get("/")
    async def root():
        return {"service": "Load-Balance FastAPI", "status": "ok"}
    
    @app.get("/api/server/stats")
    async def lb_stats():
        """è·å–è´Ÿè½½å‡è¡¡ç»Ÿè®¡ä¿¡æ¯"""
        return await get_load_balancer_stats()

    return app
